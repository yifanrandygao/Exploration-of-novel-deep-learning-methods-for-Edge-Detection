{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSCA 31009 Final Project\n",
    "### Author: Rajat Nagar, Yifan Gao\n",
    "### Date:  August 26, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prep work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os, sys\n",
    "from os.path import join, split, isdir, isfile, splitext, split, abspath, dirname\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import shutil\n",
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.autograd.variable as Variable\n",
    "import scipy.io as sio\n",
    "from torch.nn.modules.conv import _ConvNd\n",
    "from torch.nn.modules.conv import _single, _pair, _triple\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, sampler, random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchsummary import summary\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Download data & Set up folders & parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset containing test images, train images, train labels (sketch/edge of train image) and lst files (path of train and test images) from this link: https://mftp.mmcheng.net/liuyun/rcf/data/HED-BSDS.tar.gz , and extract the dataset to ROOT_DIR/data/ folder\n",
    "\n",
    "Download dataset containg test labels from this link: http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz Unzip the package and extract .mat files from BSR_bsds500.tgz\\BSR\\BSDS500\\data\\groundTruth\\test\\ to gt/ folder\n",
    "\n",
    "If you run this notebook in Linux environment, run command wget http://mftp.mmcheng.net/liuyun/rcf/data/HED-BSDS.tar.gz\n",
    "\n",
    "Download supporting package for OIS/ODS calculation from this link: https://github.com/Walstruzz/edge_eval_python/archive/refs/heads/main.zip Unzip the package, extract cxx folder to ROOT_DIR, and extract bwmorph_thin.py, correspond_pixels.py, edges_eval_dir.py from impl folder to ROOT_DIR.\\\n",
    "Open edges_eval_dir.py and modify import script \"from .bwmorph_thin import bwmorph_thin from .correspond_pixels import correspond_pixels\" to \"from bwmorph_thin import bwmorph_thin from correspond_pixels import correspond_pixels\".\\\n",
    "Note the files in cxx folder are only executable in Linux/Unix environment. They do not work in Windows. If do not have access to Linux/Unix, comment out the chunk code below under \"Measure model performance\". To compile cxx library, run command below when you use this notebook first time:\n",
    "\n",
    "cd cxx/src\\\n",
    "source build.sh\n",
    "\n",
    "Download the vgg16 pretrained backbone model from this link: https://drive.google.com/file/d/1lUhPKKj-BSOH7yQL0mOIavvrUbjydPp5/view?usp=sharing, and extract the model to ROOT_DIR folder\n",
    "\n",
    "Create a tmp/RCF folder under ROOT_DIR (if you do not create the code below will automatically create)\n",
    "\n",
    "Below is the project structure. The list files contains the path for test image, and train image and label. The gt folder contains the ground true labels for test images. The train folder has 6 folders. aug_data folders contain images we are trying to sketch/apply edge detection. aug_gt folders contain train labels, which in this project are the sketches of train images drawn by humans."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ROOT_DIR/\n",
    "|- data/\n",
    "   |- HED-BSDS/\n",
    "      |- test.lst\n",
    "      |- train_pair.lst\n",
    "      |- gt/\n",
    "         |- .mat\n",
    "      |- test/\n",
    "         |- .jpg\n",
    "      |- train/\n",
    "         |- aug_data/\n",
    "            |- .../\n",
    "               |- .jpg/\n",
    "         |- aug_data_scale_0.5/\n",
    "            |- .../\n",
    "               |- .jpg/         \n",
    "         |- aug_data_scale_1.5/\n",
    "            |- .../\n",
    "               |- .jpg/\n",
    "         |- aug_gt/\n",
    "            |- .../\n",
    "               |- .png/\n",
    "         |- aug_gt_scale_0.5/\n",
    "            |- .../\n",
    "               |- .png/\n",
    "         |- aug_gt_scale_1.5/\n",
    "            |- .../\n",
    "               |- .png/\n",
    "|- tmp/\n",
    "   |- RCF/\n",
    "|- cxx/\n",
    "   |- lib/   \n",
    "   |- src/\n",
    "    - README.md\n",
    "|- vgg16convs.mat\n",
    "|- correspond_pixels.py\n",
    "|- bwmorph_thin.py\n",
    "|- edges_eval_dir.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder/path/file variables\n",
    "Root_dir = '/home/ygao26/Desktop/final'\n",
    "# Root_dir = 'C:/Users/mars_/Documents/Personal Document/MSCA classes/MSCA 31009 1 Machine Learning Predictive Analytics/Final/'\n",
    "tmp_folder = 'tmpRCF/RCF' # tmp folder\n",
    "data_folder = 'data/HED-BSDS' # root folder of dataset\n",
    "test_lst = 'data/HED-BSDS/test.lst'\n",
    "test_lst = join(Root_dir, test_lst) # test lst file\n",
    "test_gt = join(Root_dir, 'data/HED-BSDS/gt/') # gt folder for test images\n",
    "test_pre = join(Root_dir, 'tmpRCF/RCF/epoch-10-testing-record-black') # predicted test sketches; modify accordingly\n",
    "tmp_dir = join(Root_dir, tmp_folder) # tmp directory\n",
    "if not isdir(tmp_dir):\n",
    "    os.makedirs(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters\n",
    "dft_eta = 127.5 # eta threshold to determine whether edge will be annotated\n",
    "dft_lambda = 1.1 # lambda to balance the number of positive and negative samples\n",
    "dft_bs = 1 # batch size\n",
    "dft_lr = 1e-6 # initial learning_rate\n",
    "dft_mmtum = 0.9 # momentum\n",
    "dft_wd = 2e-4 # default weight decay\n",
    "dft_ss = 3 # learning rate step size\n",
    "dft_gm = 0.1 # learning rate decay parameter: Gamma\n",
    "dft_maxep = 11 # end epoch number (# of epochs = end epoch number - start epoch number)\n",
    "dft_is = 30 # iter size\n",
    "dft_step = 1 # start epoch number (useful on restarts)\n",
    "dft_freq = 1000 # print frequency\n",
    "dft_gpu = '0' # GPU ID\n",
    "dft_tmp = tmp_folder # 'tmp folder'\n",
    "dft_datap = data_folder # root folder of dataset\n",
    "\n",
    "# enable environment for GPU use\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = dft_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define BSDS Data Loader tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image to PIL format\n",
    "def prepare_image_PIL(im):\n",
    "    im = im[:,:,::-1] - np.zeros_like(im) # rgb to bgr\n",
    "    im -= np.array((104.00698793,116.66876762,122.67891434))\n",
    "    im = np.transpose(im, (2, 0, 1)) # (H x W x C) to (C x H x W)\n",
    "    return im\n",
    "\n",
    "# Convert image to CV2 format\n",
    "def prepare_image_cv2(im):\n",
    "    im -= np.array((104.00698793,116.66876762,122.67891434))\n",
    "    im = np.transpose(im, (2, 0, 1)) # (H x W x C) to (C x H x W)\n",
    "    return im\n",
    "\n",
    "\n",
    "class BSDS_Dataloader(data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataloader BSDS500\n",
    "    \"\"\"\n",
    "    def __init__(self, root=data_folder, split='train', transform=False):\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        if self.split == 'train':\n",
    "            self.filelist = join(self.root, 'train_pair.lst')\n",
    "        elif self.split == 'test':\n",
    "            self.filelist = join(self.root, 'test.lst')\n",
    "        else:\n",
    "            raise ValueError(\"Invalid split type!\")\n",
    "        # loop thru whole list of images and labels\n",
    "        with open(self.filelist, 'r') as f:\n",
    "            self.filelist = f.readlines()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.split == \"train\":\n",
    "            # Split train images and labels\n",
    "            img_file, lb_file = self.filelist[index].split()\n",
    "            # Convert label sketch to tensor\n",
    "            lb = np.array(Image.open(join(self.root, lb_file)), dtype=np.float32)\n",
    "            # Need to squeeze label tensor to 2d from 3d\n",
    "            if lb.ndim == 3:\n",
    "                lb = np.squeeze(lb[:, :, 0])\n",
    "            assert lb.ndim == 2\n",
    "            # Add new dimension for label tensor\n",
    "            lb = lb[np.newaxis, :, :]\n",
    "            # Mask label values in a way to fit the implementation of proposed loss function\n",
    "            # 0 means no annotator labeled at this pixel\n",
    "            # 1 means all annotators have labeled at this pixel\n",
    "            # 2 means ambiguous and we need to drop\n",
    "            lb[lb == 0] = 0\n",
    "            lb[np.logical_and(lb>0, lb<dft_eta)] = 2\n",
    "            lb[lb >= dft_eta] = 1\n",
    "        else:\n",
    "            # get test image path\n",
    "            img_file = self.filelist[index].rstrip()\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            # Convert image to CV2 format if it's train\n",
    "            img = np.array(cv2.imread(join(self.root, img_file)), dtype=np.float32)\n",
    "            img = prepare_image_cv2(img)\n",
    "            return img, lb\n",
    "        else:\n",
    "            # Convert image to PIL format if it's test\n",
    "            img = np.array(Image.open(join(self.root, img_file)), dtype=np.float32)\n",
    "            img = prepare_image_PIL(img)\n",
    "            return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function uses bilinear interpolation to resize\n",
    "# image to a higher resolution one\n",
    "def make_bilinear_weights(size, num_channels):\n",
    "    ''' Make a 2D bilinear kernel suitable for upsampling\n",
    "    Stack the bilinear kernel for application to tensor,\n",
    "    using Bilinear Interpolation'''\n",
    "    factor = (size + 1) // 2\n",
    "    if size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:size, :size]\n",
    "    ## Interpolation calculation\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "             (1 - abs(og[1] - center) / factor)\n",
    "    filt = torch.from_numpy(filt)\n",
    "    w = torch.zeros(num_channels, num_channels, size, size)\n",
    "    for i in range(num_channels):\n",
    "        w[i, i] = filt\n",
    "    return w\n",
    "\n",
    "\n",
    "def crop(variable, th, tw):\n",
    "    ''' Crop the image to the desire dimension'''\n",
    "    h, w = variable.shape[2], variable.shape[3]\n",
    "    x1 = int(round((w - tw) / 2.))\n",
    "    y1 = int(round((h - th) / 2.))\n",
    "    return variable[:, :, y1 : y1 + th, x1 : x1 + tw]\n",
    "\n",
    "    \n",
    "def cross_entropy_loss_RCF(prediction, label):\n",
    "    ''' RCF cross entropy loss function:\n",
    "    prediction: predicted sketch tensor\n",
    "    label: ground truth tensor'''\n",
    "    label = label.long()\n",
    "    mask = label.float()\n",
    "    # Calculate number of positive/negative samples from ground truth\n",
    "    num_positive = torch.sum((mask==1).float()).float()\n",
    "    num_negative = torch.sum((mask==0).float()).float()\n",
    "    # Update mask, which is weight tensor for cross entropy function\n",
    "    mask[mask == 1] = 1.0 * num_negative / (num_positive + num_negative)\n",
    "    mask[mask == 0] = dft_lambda * num_positive / (num_positive + num_negative)\n",
    "    mask[mask == 2] = 0\n",
    "    # cross entropy function\n",
    "    cost = torch.nn.functional.binary_cross_entropy(\n",
    "            prediction.float(),label.float(), weight=mask, reduce=False)\n",
    "    return torch.sum(cost)\n",
    "\n",
    "class Logger(object):\n",
    "    ''' Update logs related to the model'''\n",
    "    def __init__(self, fpath=None):\n",
    "        self.console = sys.stdout\n",
    "        self.file = None\n",
    "        if fpath is not None:\n",
    "            self.file = open(fpath, 'w')\n",
    "\n",
    "    def __del__(self):\n",
    "        self.close()\n",
    "\n",
    "    def __enter__(self):\n",
    "        pass\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.close()\n",
    "\n",
    "    def write(self, msg):\n",
    "        self.console.write(msg)\n",
    "        if self.file is not None:\n",
    "            self.file.write(msg)\n",
    "\n",
    "    def flush(self):\n",
    "        self.console.flush()\n",
    "        if self.file is not None:\n",
    "            self.file.flush()\n",
    "            os.fsync(self.file.fileno())\n",
    "\n",
    "    def close(self):\n",
    "        self.console.close()\n",
    "        if self.file is not None:\n",
    "            self.file.close()\n",
    "\n",
    "class Averagvalue(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def save_checkpoint(state, filename='checkpoint.pth'):\n",
    "    \"\"\"Save pre-trained models per epoch\"\"\"\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_vgg16pretrain(model, vggmodel='vgg16convs.mat'):\n",
    "    \"\"\"Update weights and bias of vgg 16 model to RCF\n",
    "    model as initial weights and bias, since vgg 16 \n",
    "    is the backbone of RCF\"\"\"\n",
    "    vgg16 = sio.loadmat(vggmodel)\n",
    "    torch_params =  model.state_dict()\n",
    "    for k in vgg16.keys():\n",
    "        name_par = k.split('-')\n",
    "        size = len(name_par)\n",
    "        # Update when there is a CNN layer\n",
    "        if size  == 2:\n",
    "            name_space = name_par[0] + '.' + name_par[1]\n",
    "            data = np.squeeze(vgg16[k])\n",
    "            torch_params[name_space] = torch.from_numpy(data)\n",
    "    model.load_state_dict(torch_params)\n",
    "\n",
    "def load_vgg19pretrain(model):\n",
    "    \"\"\"Update weights and bias of vgg 19 model to RCF\n",
    "    model as initial weights and bias, since vgg 19 \n",
    "    is the backbone of RCF\"\"\"\n",
    "    vgg19 = torchvision.models.vgg19(pretrained=True)\n",
    "    torch_params =  model.state_dict()\n",
    "    vgg19_keys = ['conv1_1','relu','conv1_2','relu','maxpool','conv2_1','relu','conv2_2','relu','maxpool',\n",
    "                  'conv3_1','relu','conv3_2','relu','conv3_3','relu','conv3_4','relu','maxpool','conv4_1',\n",
    "                  'relu','conv4_2','relu','conv4_3','relu','conv4_4','relu','maxpool','conv5_1','relu',\n",
    "                  'conv5_2','relu','conv5_3','relu','conv5_4','relu','maxpool']\n",
    "    for k in vgg19_keys:\n",
    "        # Update when there is a CNN layer\n",
    "        if '_' in k:\n",
    "            name_space_wt = k + '.weight'\n",
    "            name_space_bs = k + '.bias'\n",
    "            data_wt = vgg19.features[vgg19_keys.index(k)].weight.detach().numpy()\n",
    "            data_bs = vgg19.features[vgg19_keys.index(k)].bias.detach().numpy()\n",
    "            torch_params[name_space_wt] = torch.from_numpy(data_wt)\n",
    "            torch_params[name_space_bs] = torch.from_numpy(data_bs)\n",
    "    model.load_state_dict(torch_params)\n",
    "    \n",
    "def weights_init(m):\n",
    "    \"\"\"Function to initialize weights\"\"\"\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        # xavier(m.weight.data)\n",
    "        m.weight.data.normal_(0, 0.01)\n",
    "        if m.weight.data.shape == torch.Size([1, 5, 1, 1]):\n",
    "            # for new_score_weight\n",
    "            torch.nn.init.constant_(m.weight, 0.2) # as per https://github.com/yun-liu/rcf\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define RCF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCF stands for Richer Convolutional Features, which encapsulates all convolutional features into more discriminative representation, which makes good usage of rich feature hierarchies, and is amenable to training via backpropagation.\\\n",
    "The author of RCF model is Yun Liu and this is the link to his paper:\n",
    "https://arxiv.org/pdf/1612.02103.pdf \\\n",
    "My work is also inspired by a Github page, where the authur put a Pytorch implementation of the original model: https://github.com/balajiselvaraj1601/RCF_Pytorch_Updated \\\n",
    "The code below replicates what Yun did with a split in train dataset to evaluate overfitting/underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RCF(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Instantiate all the modules for RCF\n",
    "        super().__init__()\n",
    "#         super(RCF, self).__init__()\n",
    "        #lr 1 2 decay 1 0\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        \n",
    "#         self.conv3_4 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        \n",
    "#         self.conv4_4 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3,\n",
    "                        stride=1, padding=2, dilation=2)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3,\n",
    "                        stride=1, padding=2, dilation=2)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3,\n",
    "                        stride=1, padding=2, dilation=2)\n",
    "        \n",
    "#         self.conv5_4 = nn.Conv2d(512, 512, kernel_size=3,\n",
    "#                         stride=1, padding=2, dilation=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "        self.maxpool4 = nn.MaxPool2d(2, stride=1, ceil_mode=True)\n",
    "\n",
    "\n",
    "        #lr 0.1 0.2 decay 1 0\n",
    "        self.conv1_1_down = nn.Conv2d(64, 21, 1, padding=0)\n",
    "        self.conv1_2_down = nn.Conv2d(64, 21, 1, padding=0)\n",
    "\n",
    "        self.conv2_1_down = nn.Conv2d(128, 21, 1, padding=0)\n",
    "        self.conv2_2_down = nn.Conv2d(128, 21, 1, padding=0)\n",
    "\n",
    "        self.conv3_1_down = nn.Conv2d(256, 21, 1, padding=0)\n",
    "        self.conv3_2_down = nn.Conv2d(256, 21, 1, padding=0)\n",
    "        self.conv3_3_down = nn.Conv2d(256, 21, 1, padding=0)\n",
    "        \n",
    "#         self.conv3_4_down = nn.Conv2d(256, 21, 1, padding=0)\n",
    "        \n",
    "        self.conv4_1_down = nn.Conv2d(512, 21, 1, padding=0)\n",
    "        self.conv4_2_down = nn.Conv2d(512, 21, 1, padding=0)\n",
    "        self.conv4_3_down = nn.Conv2d(512, 21, 1, padding=0)\n",
    "        \n",
    "#         self.conv4_4_down = nn.Conv2d(512, 21, 1, padding=0)\n",
    "        \n",
    "        self.conv5_1_down = nn.Conv2d(512, 21, 1, padding=0)\n",
    "        self.conv5_2_down = nn.Conv2d(512, 21, 1, padding=0)\n",
    "        self.conv5_3_down = nn.Conv2d(512, 21, 1, padding=0)\n",
    "        \n",
    "#         self.conv5_4_down = nn.Conv2d(512, 21, 1, padding=0)\n",
    "        \n",
    "        #lr 0.01 0.02 decay 1 0\n",
    "        self.score_dsn1 = nn.Conv2d(21, 1, 1)\n",
    "        self.score_dsn2 = nn.Conv2d(21, 1, 1)\n",
    "        self.score_dsn3 = nn.Conv2d(21, 1, 1)\n",
    "        self.score_dsn4 = nn.Conv2d(21, 1, 1)\n",
    "        self.score_dsn5 = nn.Conv2d(21, 1, 1)\n",
    "        #lr 0.001 0.002 decay 1 0\n",
    "        self.score_final = nn.Conv2d(5, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward function defines the network structure\n",
    "        # and how to get the output of the neural net\n",
    "        img_H, img_W = x.shape[2], x.shape[3]\n",
    "        conv1_1 = self.relu(self.conv1_1(x))\n",
    "        conv1_2 = self.relu(self.conv1_2(conv1_1))\n",
    "        pool1   = self.maxpool(conv1_2)\n",
    "\n",
    "        conv2_1 = self.relu(self.conv2_1(pool1))\n",
    "        conv2_2 = self.relu(self.conv2_2(conv2_1))\n",
    "        pool2   = self.maxpool(conv2_2)\n",
    "\n",
    "        conv3_1 = self.relu(self.conv3_1(pool2))\n",
    "        conv3_2 = self.relu(self.conv3_2(conv3_1))\n",
    "        conv3_3 = self.relu(self.conv3_3(conv3_2))\n",
    "        \n",
    "#         conv3_4 = self.relu(self.conv3_4(conv3_3))\n",
    "        pool3   = self.maxpool(conv3_3)\n",
    "\n",
    "        conv4_1 = self.relu(self.conv4_1(pool3))\n",
    "        conv4_2 = self.relu(self.conv4_2(conv4_1))\n",
    "        conv4_3 = self.relu(self.conv4_3(conv4_2))\n",
    "        \n",
    "#         conv4_4 = self.relu(self.conv4_4(conv4_3))\n",
    "        pool4   = self.maxpool4(conv4_3)\n",
    "\n",
    "        conv5_1 = self.relu(self.conv5_1(pool4))\n",
    "        conv5_2 = self.relu(self.conv5_2(conv5_1))\n",
    "        conv5_3 = self.relu(self.conv5_3(conv5_2))\n",
    "        \n",
    "#         conv5_4 = self.relu(self.conv5_4(conv5_3))\n",
    "        \n",
    "        conv1_1_down = self.conv1_1_down(conv1_1)\n",
    "        conv1_2_down = self.conv1_2_down(conv1_2)\n",
    "        conv2_1_down = self.conv2_1_down(conv2_1)\n",
    "        conv2_2_down = self.conv2_2_down(conv2_2)\n",
    "        conv3_1_down = self.conv3_1_down(conv3_1)\n",
    "        conv3_2_down = self.conv3_2_down(conv3_2)\n",
    "        conv3_3_down = self.conv3_3_down(conv3_3)\n",
    "        \n",
    "#         conv3_4_down = self.conv3_4_down(conv3_4)\n",
    "        \n",
    "        conv4_1_down = self.conv4_1_down(conv4_1)\n",
    "        conv4_2_down = self.conv4_2_down(conv4_2)\n",
    "        conv4_3_down = self.conv4_3_down(conv4_3)\n",
    "        \n",
    "#         conv4_4_down = self.conv4_4_down(conv4_4)\n",
    "        \n",
    "        conv5_1_down = self.conv5_1_down(conv5_1)\n",
    "        conv5_2_down = self.conv5_2_down(conv5_2)\n",
    "        conv5_3_down = self.conv5_3_down(conv5_3)\n",
    "        \n",
    "#         conv5_4_down = self.conv5_4_down(conv5_4)\n",
    "        \n",
    "        so1_out = self.score_dsn1(conv1_1_down + conv1_2_down)\n",
    "        so2_out = self.score_dsn2(conv2_1_down + conv2_2_down)\n",
    "        so3_out = self.score_dsn3(conv3_1_down + conv3_2_down + conv3_3_down)\n",
    "        so4_out = self.score_dsn4(conv4_1_down + conv4_2_down + conv4_3_down)\n",
    "        so5_out = self.score_dsn5(conv5_1_down + conv5_2_down + conv5_3_down)\n",
    "        ## transpose and crop way \n",
    "        weight_deconv2 =  make_bilinear_weights(4, 1).cuda() # cuda method is to move tensors and models from cpu to gpu\n",
    "        weight_deconv3 =  make_bilinear_weights(8, 1).cuda()\n",
    "        weight_deconv4 =  make_bilinear_weights(16, 1).cuda()\n",
    "        weight_deconv5 =  make_bilinear_weights(16, 1).cuda()\n",
    "\n",
    "        upsample2 = torch.nn.functional.conv_transpose2d(so2_out, weight_deconv2, stride=2)\n",
    "        upsample3 = torch.nn.functional.conv_transpose2d(so3_out, weight_deconv3, stride=4)\n",
    "        upsample4 = torch.nn.functional.conv_transpose2d(so4_out, weight_deconv4, stride=8)\n",
    "        upsample5 = torch.nn.functional.conv_transpose2d(so5_out, weight_deconv5, stride=8)\n",
    "        ### center crop\n",
    "        so1 = crop(so1_out, img_H, img_W)\n",
    "        so2 = crop(upsample2, img_H, img_W)\n",
    "        so3 = crop(upsample3, img_H, img_W)\n",
    "        so4 = crop(upsample4, img_H, img_W)\n",
    "        so5 = crop(upsample5, img_H, img_W)\n",
    "\n",
    "        fusecat = torch.cat((so1, so2, so3, so4, so5), dim=1)\n",
    "        fuse = self.score_final(fusecat)\n",
    "        results = [so1, so2, so3, so4, so5, fuse]\n",
    "        results = [torch.sigmoid(r) for r in results]\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, epoch, save_dir):\n",
    "    batch_time = Averagvalue()\n",
    "    data_time = Averagvalue()\n",
    "    losses = Averagvalue()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "    epoch_loss = []\n",
    "    counter = 0\n",
    "    for i, (image, label) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        image, label = image.cuda(), label.cuda()\n",
    "        outputs = model(image)\n",
    "        loss = torch.zeros(1).cuda()\n",
    "        for o in outputs:\n",
    "            loss = loss + cross_entropy_loss_RCF(o, label)\n",
    "        counter += 1\n",
    "        loss = loss / dft_is\n",
    "        loss.backward() # back propagation\n",
    "        # Gradient descent every dft_is, which is iteration size\n",
    "        if counter == dft_is:\n",
    "            # Perform a single optimization step\n",
    "            optimizer.step()\n",
    "            # Set the gradients of all optimized torch.Tensor s to zero\n",
    "            optimizer.zero_grad()\n",
    "            counter = 0\n",
    "        # measure accuracy and record loss\n",
    "        losses.update(loss.item(), image.size(0))\n",
    "        epoch_loss.append(loss.item())\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        # display and logging\n",
    "        if not isdir(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        # Print log and save outputs every frequency, which by default is 1000\n",
    "        if i % dft_freq == 0:\n",
    "            info = 'Epoch: [{0}/{1}][{2}/{3}] '.format(epoch, dft_maxep - 1, i, len(train_loader)) + \\\n",
    "                   'Time {batch_time.val:.3f} (avg:{batch_time.avg:.3f}) '.format(batch_time=batch_time) + \\\n",
    "                   'Loss {loss.val:f} (avg:{loss.avg:f}) '.format(\n",
    "                       loss=losses)\n",
    "            print(info)\n",
    "            # label_out is edge with label having pixel equals to 1\n",
    "            label_out = torch.eq(label, 1).float()\n",
    "            # append label_out to outputs\n",
    "            outputs.append(label_out)\n",
    "            _, _, H, W = outputs[0].shape # H W: predicted sketch height and width\n",
    "            all_results = torch.zeros((len(outputs), 1, H, W))\n",
    "            for j in range(len(outputs)):\n",
    "                # Reduce dimensions from 4d tensor to 2d tensor\n",
    "                all_results[j, 0, :, :] = outputs[j][0, 0, :, :]\n",
    "            torchvision.utils.save_image(1-all_results, join(save_dir, \"iter-%d.jpg\" % i))\n",
    "    return losses.avg, epoch_loss\n",
    "\n",
    "def validation_loss(val_loader, model, optimizer, epoch):\n",
    "    model.eval()\n",
    "    losses = Averagvalue()\n",
    "    epoch_loss = []\n",
    "    counter = 0\n",
    "    for i, (image, label) in enumerate(val_loader):\n",
    "        image, label = image.cuda(), label.cuda()\n",
    "        outputs = model(image)\n",
    "        loss = torch.zeros(1).cuda()\n",
    "        for o in outputs:\n",
    "            loss = loss + cross_entropy_loss_RCF(o, label)\n",
    "        counter += 1\n",
    "        loss = loss / dft_is\n",
    "        loss.backward() # back propagation\n",
    "        # Gradient descent every dft_is, which is iteration size\n",
    "        if counter == dft_is:\n",
    "            # Perform a single optimization step\n",
    "            optimizer.step()\n",
    "            # Set the gradients of all optimized torch.Tensor s to zero\n",
    "            optimizer.zero_grad()\n",
    "            counter = 0\n",
    "        # measure accuracy and record loss\n",
    "        losses.update(loss.item(), image.size(0))\n",
    "        epoch_loss.append(loss.item())\n",
    "    return losses.avg, epoch_loss\n",
    "\n",
    "\n",
    "def multiscale_test(model, test_loader, epoch, test_list, save_dir):\n",
    "    model.eval()\n",
    "    if not isdir(save_dir):\n",
    "        os.makedirs(save_dir + ('-black'))\n",
    "        os.makedirs(save_dir + ('-white'))\n",
    "        os.makedirs(save_dir + ('-graduate'))\n",
    "    scale = [0.5, 1, 1.5]\n",
    "    for idx, image in enumerate(test_loader):\n",
    "        filename = splitext(test_list[idx])[0]\n",
    "        image = image[0]\n",
    "        image_in = image.numpy().transpose((1,2,0))\n",
    "        _, H, W = image.shape\n",
    "        multi_fuse = np.zeros((H, W), np.float32)\n",
    "        for k in range(0, len(scale)):\n",
    "            im_ = cv2.resize(image_in, None, fx=scale[k], fy=scale[k], interpolation=cv2.INTER_LINEAR)\n",
    "            im_ = im_.transpose((2,0,1))\n",
    "            results = model(torch.unsqueeze(torch.from_numpy(im_).cuda(), 0))\n",
    "            result = torch.squeeze(results[-1].detach()).cpu().numpy()\n",
    "            if k == 1:\n",
    "                results_all = torch.zeros((len(results), 1, H, W))\n",
    "                for i in range(len(results)):\n",
    "                    results_all[i, 0, :, :] = results[i]\n",
    "                torchvision.utils.save_image(1-results_all, join(save_dir + ('-graduate'), \"%s.png\" % filename))\n",
    "            fuse = cv2.resize(result, (W, H), interpolation=cv2.INTER_LINEAR)\n",
    "            multi_fuse += fuse\n",
    "        multi_fuse = multi_fuse / len(scale)\n",
    "        # White background\n",
    "        result_out = Image.fromarray(((1-multi_fuse) * 255).astype(np.uint8))\n",
    "        result_out.save(join(save_dir + ('-white'), \"%s.jpg\" % filename))\n",
    "        # Black background\n",
    "        result_out_test = Image.fromarray((multi_fuse * 255).astype(np.uint8))\n",
    "        result_out_test.save(join(save_dir + ('-black'), \"%s.png\" % filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define and execute main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ygao26/.local/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/ygao26/.local/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10][0/23040] Time 0.632 (avg:0.632) Loss 200.822144 (avg:200.822144) \n",
      "Epoch: [1/10][1000/23040] Time 0.734 (avg:0.225) Loss 142.575577 (avg:112.596015) \n",
      "Epoch: [1/10][2000/23040] Time 0.070 (avg:0.225) Loss 0.611754 (avg:94.885751) \n",
      "Epoch: [1/10][3000/23040] Time 0.296 (avg:0.225) Loss 29.371000 (avg:88.911686) \n",
      "Epoch: [1/10][4000/23040] Time 0.091 (avg:0.224) Loss 6.390559 (avg:84.998538) \n",
      "Epoch: [1/10][5000/23040] Time 0.140 (avg:0.223) Loss 101.772972 (avg:81.732516) \n",
      "Epoch: [1/10][6000/23040] Time 0.280 (avg:0.223) Loss 47.751476 (avg:80.375998) \n",
      "Epoch: [1/10][7000/23040] Time 0.401 (avg:0.224) Loss 139.257690 (avg:79.093893) \n",
      "Epoch: [1/10][8000/23040] Time 0.059 (avg:0.224) Loss 0.000000 (avg:77.883816) \n",
      "Epoch: [1/10][9000/23040] Time 0.140 (avg:0.223) Loss 62.506199 (avg:76.669833) \n",
      "Epoch: [1/10][10000/23040] Time 0.383 (avg:0.223) Loss 50.471928 (avg:76.218242) \n",
      "Epoch: [1/10][11000/23040] Time 0.308 (avg:0.223) Loss 119.499611 (avg:75.378703) \n",
      "Epoch: [1/10][12000/23040] Time 0.245 (avg:0.223) Loss 276.634033 (avg:74.704992) \n",
      "Epoch: [1/10][13000/23040] Time 0.381 (avg:0.223) Loss 49.827309 (avg:74.092335) \n",
      "Epoch: [1/10][14000/23040] Time 0.299 (avg:0.224) Loss 99.225960 (avg:73.463981) \n",
      "Epoch: [1/10][15000/23040] Time 0.060 (avg:0.224) Loss 5.153048 (avg:73.069482) \n",
      "Epoch: [1/10][16000/23040] Time 0.333 (avg:0.224) Loss 200.855347 (avg:73.022880) \n",
      "Epoch: [1/10][17000/23040] Time 0.752 (avg:0.224) Loss 185.742447 (avg:72.416235) \n",
      "Epoch: [1/10][18000/23040] Time 0.737 (avg:0.224) Loss 92.790909 (avg:72.074056) \n",
      "Epoch: [1/10][19000/23040] Time 0.728 (avg:0.223) Loss 198.859665 (avg:71.649889) \n",
      "Epoch: [1/10][20000/23040] Time 0.306 (avg:0.223) Loss 56.116360 (avg:71.425920) \n",
      "Epoch: [1/10][21000/23040] Time 0.336 (avg:0.223) Loss 376.224152 (avg:71.167909) \n",
      "Epoch: [1/10][22000/23040] Time 0.518 (avg:0.223) Loss 269.462585 (avg:71.075973) \n",
      "Epoch: [1/10][23000/23040] Time 0.206 (avg:0.223) Loss 35.597019 (avg:70.777280) \n",
      "Epoch: [2/10][0/23040] Time 0.177 (avg:0.177) Loss 76.300690 (avg:76.300690) \n",
      "Epoch: [2/10][1000/23040] Time 0.294 (avg:0.225) Loss 30.815039 (avg:62.418826) \n",
      "Epoch: [2/10][2000/23040] Time 0.154 (avg:0.227) Loss 100.153442 (avg:63.517297) \n",
      "Epoch: [2/10][3000/23040] Time 0.296 (avg:0.226) Loss 29.823629 (avg:64.185127) \n",
      "Epoch: [2/10][4000/23040] Time 0.068 (avg:0.224) Loss 1.491902 (avg:63.405884) \n",
      "Epoch: [2/10][5000/23040] Time 0.101 (avg:0.225) Loss 0.782146 (avg:63.277495) \n",
      "Epoch: [2/10][6000/23040] Time 0.280 (avg:0.224) Loss 70.611023 (avg:63.582070) \n",
      "Epoch: [2/10][7000/23040] Time 0.145 (avg:0.224) Loss 49.521812 (avg:63.598762) \n",
      "Epoch: [2/10][8000/23040] Time 0.058 (avg:0.224) Loss 0.000000 (avg:63.671930) \n",
      "Epoch: [2/10][9000/23040] Time 0.404 (avg:0.224) Loss 151.271606 (avg:63.767023) \n",
      "Epoch: [2/10][10000/23040] Time 0.059 (avg:0.224) Loss 0.290169 (avg:63.556802) \n",
      "Epoch: [2/10][11000/23040] Time 0.191 (avg:0.222) Loss 32.417149 (avg:63.182778) \n",
      "Epoch: [2/10][12000/23040] Time 0.294 (avg:0.223) Loss 191.366196 (avg:63.365293) \n",
      "Epoch: [2/10][13000/23040] Time 0.148 (avg:0.222) Loss 25.183893 (avg:63.051220) \n",
      "Epoch: [2/10][14000/23040] Time 0.735 (avg:0.223) Loss 145.894241 (avg:63.006271) \n",
      "Epoch: [2/10][15000/23040] Time 0.287 (avg:0.223) Loss 9.426408 (avg:63.039182) \n",
      "Epoch: [2/10][16000/23040] Time 0.102 (avg:0.223) Loss 0.000000 (avg:62.919719) \n",
      "Epoch: [2/10][17000/23040] Time 0.245 (avg:0.223) Loss 71.047264 (avg:62.757448) \n",
      "Epoch: [2/10][18000/23040] Time 0.137 (avg:0.223) Loss 80.989426 (avg:62.683260) \n",
      "Epoch: [2/10][19000/23040] Time 0.463 (avg:0.224) Loss 55.406090 (avg:62.741843) \n",
      "Epoch: [2/10][20000/23040] Time 0.402 (avg:0.224) Loss 92.656326 (avg:62.640170) \n",
      "Epoch: [2/10][21000/23040] Time 0.100 (avg:0.223) Loss 0.474573 (avg:62.381621) \n",
      "Epoch: [2/10][22000/23040] Time 0.285 (avg:0.223) Loss 100.670074 (avg:62.344536) \n",
      "Epoch: [2/10][23000/23040] Time 0.397 (avg:0.223) Loss 44.729588 (avg:62.188294) \n",
      "Epoch: [3/10][0/23040] Time 0.173 (avg:0.173) Loss 0.224652 (avg:0.224652) \n",
      "Epoch: [3/10][1000/23040] Time 0.293 (avg:0.222) Loss 85.807419 (avg:58.804322) \n",
      "Epoch: [3/10][2000/23040] Time 0.074 (avg:0.224) Loss 0.139536 (avg:57.639142) \n",
      "Epoch: [3/10][3000/23040] Time 0.395 (avg:0.222) Loss 58.738956 (avg:59.217338) \n",
      "Epoch: [3/10][4000/23040] Time 0.084 (avg:0.222) Loss 0.904065 (avg:59.234233) \n",
      "Epoch: [3/10][5000/23040] Time 0.525 (avg:0.223) Loss 113.104271 (avg:60.010443) \n",
      "Epoch: [3/10][6000/23040] Time 0.743 (avg:0.223) Loss 74.280212 (avg:60.348128) \n",
      "Epoch: [3/10][7000/23040] Time 0.060 (avg:0.224) Loss 0.834094 (avg:60.645361) \n",
      "Epoch: [3/10][8000/23040] Time 0.296 (avg:0.224) Loss 25.736328 (avg:60.374539) \n",
      "Epoch: [3/10][9000/23040] Time 0.253 (avg:0.223) Loss 244.716583 (avg:60.453630) \n",
      "Epoch: [3/10][10000/23040] Time 0.081 (avg:0.223) Loss 0.271720 (avg:60.113882) \n",
      "Epoch: [3/10][11000/23040] Time 0.294 (avg:0.223) Loss 43.172123 (avg:60.233847) \n",
      "Epoch: [3/10][12000/23040] Time 0.150 (avg:0.223) Loss 65.457458 (avg:59.815186) \n",
      "Epoch: [3/10][13000/23040] Time 0.344 (avg:0.223) Loss 189.543091 (avg:59.744437) \n",
      "Epoch: [3/10][14000/23040] Time 0.148 (avg:0.223) Loss 156.123199 (avg:59.696585) \n",
      "Epoch: [3/10][15000/23040] Time 0.081 (avg:0.223) Loss 0.565916 (avg:59.574009) \n",
      "Epoch: [3/10][16000/23040] Time 0.275 (avg:0.223) Loss 51.269951 (avg:59.326412) \n",
      "Epoch: [3/10][17000/23040] Time 0.396 (avg:0.222) Loss 38.950520 (avg:59.269868) \n",
      "Epoch: [3/10][18000/23040] Time 0.084 (avg:0.222) Loss 0.301362 (avg:59.082026) \n",
      "Epoch: [3/10][19000/23040] Time 0.136 (avg:0.222) Loss 42.650620 (avg:59.230559) \n",
      "Epoch: [3/10][20000/23040] Time 0.746 (avg:0.223) Loss 190.603088 (avg:59.351441) \n",
      "Epoch: [3/10][21000/23040] Time 0.134 (avg:0.223) Loss 13.782022 (avg:59.375575) \n",
      "Epoch: [3/10][22000/23040] Time 0.085 (avg:0.223) Loss 0.304511 (avg:59.407327) \n",
      "Epoch: [3/10][23000/23040] Time 0.193 (avg:0.223) Loss 7.782171 (avg:59.378016) \n",
      "Epoch: [4/10][0/23040] Time 0.095 (avg:0.095) Loss 0.946353 (avg:0.946353) \n",
      "Epoch: [4/10][1000/23040] Time 0.145 (avg:0.230) Loss 81.527481 (avg:58.779524) \n",
      "Epoch: [4/10][2000/23040] Time 0.522 (avg:0.228) Loss 103.167923 (avg:58.923988) \n",
      "Epoch: [4/10][3000/23040] Time 0.194 (avg:0.225) Loss 73.875526 (avg:57.848173) \n",
      "Epoch: [4/10][4000/23040] Time 0.529 (avg:0.223) Loss 174.814011 (avg:58.512382) \n",
      "Epoch: [4/10][5000/23040] Time 0.144 (avg:0.222) Loss 78.315521 (avg:57.945112) \n",
      "Epoch: [4/10][6000/23040] Time 0.263 (avg:0.223) Loss 95.755753 (avg:58.054959) \n",
      "Epoch: [4/10][7000/23040] Time 0.071 (avg:0.222) Loss 0.720562 (avg:57.903365) \n",
      "Epoch: [4/10][8000/23040] Time 0.288 (avg:0.223) Loss 31.536020 (avg:58.241792) \n",
      "Epoch: [4/10][9000/23040] Time 0.084 (avg:0.222) Loss 1.054594 (avg:57.803449) \n",
      "Epoch: [4/10][10000/23040] Time 0.741 (avg:0.222) Loss 123.465965 (avg:57.752017) \n",
      "Epoch: [4/10][11000/23040] Time 0.072 (avg:0.222) Loss 0.145671 (avg:57.607907) \n",
      "Epoch: [4/10][12000/23040] Time 0.288 (avg:0.222) Loss 72.241051 (avg:57.715510) \n",
      "Epoch: [4/10][13000/23040] Time 0.347 (avg:0.222) Loss 140.525818 (avg:57.457898) \n",
      "Epoch: [4/10][14000/23040] Time 0.084 (avg:0.222) Loss 0.161473 (avg:57.290097) \n",
      "Epoch: [4/10][15000/23040] Time 0.152 (avg:0.222) Loss 42.213886 (avg:57.473707) \n",
      "Epoch: [4/10][16000/23040] Time 0.149 (avg:0.223) Loss 37.934311 (avg:57.404310) \n",
      "Epoch: [4/10][17000/23040] Time 0.396 (avg:0.223) Loss 46.772240 (avg:57.210623) \n",
      "Epoch: [4/10][18000/23040] Time 0.061 (avg:0.223) Loss 5.313735 (avg:57.244706) \n",
      "Epoch: [4/10][19000/23040] Time 0.141 (avg:0.223) Loss 38.477715 (avg:57.099192) \n",
      "Epoch: [4/10][20000/23040] Time 0.193 (avg:0.223) Loss 63.175652 (avg:57.071940) \n",
      "Epoch: [4/10][21000/23040] Time 0.276 (avg:0.223) Loss 42.814373 (avg:56.938820) \n",
      "Epoch: [4/10][22000/23040] Time 0.292 (avg:0.223) Loss 23.323013 (avg:56.983133) \n",
      "Epoch: [4/10][23000/23040] Time 0.183 (avg:0.223) Loss 73.876747 (avg:57.006601) \n",
      "Epoch: [5/10][0/23040] Time 0.090 (avg:0.090) Loss 0.000000 (avg:0.000000) \n",
      "Epoch: [5/10][1000/23040] Time 0.280 (avg:0.224) Loss 45.109451 (avg:58.374947) \n",
      "Epoch: [5/10][2000/23040] Time 0.073 (avg:0.220) Loss 1.262885 (avg:56.950436) \n",
      "Epoch: [5/10][3000/23040] Time 0.058 (avg:0.221) Loss 0.331644 (avg:56.156660) \n",
      "Epoch: [5/10][4000/23040] Time 0.260 (avg:0.222) Loss 104.733322 (avg:56.172818) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/10][5000/23040] Time 0.077 (avg:0.220) Loss 0.820813 (avg:55.841633) \n",
      "Epoch: [5/10][6000/23040] Time 0.320 (avg:0.222) Loss 50.253490 (avg:56.489625) \n",
      "Epoch: [5/10][7000/23040] Time 0.195 (avg:0.222) Loss 27.610153 (avg:56.655558) \n",
      "Epoch: [5/10][8000/23040] Time 0.550 (avg:0.222) Loss 54.170742 (avg:56.272026) \n",
      "Epoch: [5/10][9000/23040] Time 0.058 (avg:0.222) Loss 4.479629 (avg:56.124596) \n",
      "Epoch: [5/10][10000/23040] Time 0.074 (avg:0.223) Loss 3.216249 (avg:56.203951) \n",
      "Epoch: [5/10][11000/23040] Time 0.146 (avg:0.224) Loss 24.016336 (avg:56.740692) \n",
      "Epoch: [5/10][12000/23040] Time 0.059 (avg:0.225) Loss 6.811236 (avg:56.573203) \n",
      "Epoch: [5/10][13000/23040] Time 0.264 (avg:0.224) Loss 85.177696 (avg:56.413838) \n",
      "Epoch: [5/10][14000/23040] Time 0.057 (avg:0.225) Loss 1.736758 (avg:56.874969) \n",
      "Epoch: [5/10][15000/23040] Time 0.272 (avg:0.225) Loss 123.129608 (avg:56.464514) \n",
      "Epoch: [5/10][16000/23040] Time 0.148 (avg:0.225) Loss 91.733452 (avg:56.416089) \n",
      "Epoch: [5/10][17000/23040] Time 0.295 (avg:0.225) Loss 62.474705 (avg:56.693530) \n",
      "Epoch: [5/10][18000/23040] Time 0.059 (avg:0.225) Loss 2.248657 (avg:56.927279) \n",
      "Epoch: [5/10][19000/23040] Time 0.545 (avg:0.226) Loss 86.735817 (avg:56.904869) \n",
      "Epoch: [5/10][20000/23040] Time 0.533 (avg:0.226) Loss 135.648117 (avg:56.999377) \n",
      "Epoch: [5/10][21000/23040] Time 0.139 (avg:0.226) Loss 39.612274 (avg:56.781460) \n",
      "Epoch: [5/10][22000/23040] Time 0.073 (avg:0.226) Loss 0.082730 (avg:56.667169) \n",
      "Epoch: [5/10][23000/23040] Time 0.293 (avg:0.225) Loss 62.482426 (avg:56.573612) \n",
      "Epoch: [6/10][0/23040] Time 0.193 (avg:0.193) Loss 0.106012 (avg:0.106012) \n",
      "Epoch: [6/10][1000/23040] Time 0.288 (avg:0.217) Loss 7.638040 (avg:53.068956) \n",
      "Epoch: [6/10][2000/23040] Time 0.302 (avg:0.225) Loss 71.098495 (avg:57.279472) \n",
      "Epoch: [6/10][3000/23040] Time 0.061 (avg:0.226) Loss 0.311217 (avg:56.301273) \n",
      "Epoch: [6/10][4000/23040] Time 0.060 (avg:0.227) Loss 11.974977 (avg:56.399691) \n",
      "Epoch: [6/10][5000/23040] Time 0.296 (avg:0.226) Loss 71.889244 (avg:55.757133) \n",
      "Epoch: [6/10][6000/23040] Time 0.289 (avg:0.225) Loss 30.172491 (avg:55.922264) \n",
      "Epoch: [6/10][7000/23040] Time 0.146 (avg:0.223) Loss 36.756615 (avg:55.754195) \n",
      "Epoch: [6/10][8000/23040] Time 0.382 (avg:0.224) Loss 16.406963 (avg:55.938776) \n",
      "Epoch: [6/10][9000/23040] Time 0.073 (avg:0.224) Loss 0.451372 (avg:56.199852) \n",
      "Epoch: [6/10][10000/23040] Time 0.738 (avg:0.225) Loss 185.493484 (avg:56.374181) \n",
      "Epoch: [6/10][11000/23040] Time 0.384 (avg:0.224) Loss 55.219738 (avg:56.055702) \n",
      "Epoch: [6/10][12000/23040] Time 0.059 (avg:0.224) Loss 0.579793 (avg:56.091199) \n",
      "Epoch: [6/10][13000/23040] Time 0.734 (avg:0.223) Loss 99.710838 (avg:55.919003) \n",
      "Epoch: [6/10][14000/23040] Time 0.285 (avg:0.223) Loss 32.109505 (avg:56.149416) \n",
      "Epoch: [6/10][15000/23040] Time 0.105 (avg:0.224) Loss 0.054734 (avg:56.097337) \n",
      "Epoch: [6/10][16000/23040] Time 0.058 (avg:0.224) Loss 1.982404 (avg:56.056312) \n",
      "Epoch: [6/10][17000/23040] Time 0.143 (avg:0.224) Loss 46.981018 (avg:55.978173) \n",
      "Epoch: [6/10][18000/23040] Time 0.303 (avg:0.224) Loss 16.992058 (avg:56.163895) \n",
      "Epoch: [6/10][19000/23040] Time 0.061 (avg:0.223) Loss 3.032480 (avg:56.163163) \n",
      "Epoch: [6/10][20000/23040] Time 0.475 (avg:0.223) Loss 85.980606 (avg:56.028672) \n",
      "Epoch: [6/10][21000/23040] Time 0.196 (avg:0.223) Loss 40.801785 (avg:56.182555) \n",
      "Epoch: [6/10][22000/23040] Time 0.058 (avg:0.224) Loss 1.497776 (avg:56.325074) \n",
      "Epoch: [6/10][23000/23040] Time 0.139 (avg:0.224) Loss 81.319160 (avg:56.280627) \n",
      "Epoch: [7/10][0/23040] Time 0.223 (avg:0.223) Loss 13.939651 (avg:13.939651) \n",
      "Epoch: [7/10][1000/23040] Time 0.061 (avg:0.226) Loss 0.531581 (avg:53.951020) \n",
      "Epoch: [7/10][2000/23040] Time 0.741 (avg:0.225) Loss 79.183403 (avg:54.508197) \n",
      "Epoch: [7/10][3000/23040] Time 0.075 (avg:0.223) Loss 2.320798 (avg:54.245368) \n",
      "Epoch: [7/10][4000/23040] Time 0.293 (avg:0.223) Loss 45.600647 (avg:55.722461) \n",
      "Epoch: [7/10][5000/23040] Time 0.351 (avg:0.225) Loss 59.477242 (avg:56.617031) \n",
      "Epoch: [7/10][6000/23040] Time 0.079 (avg:0.225) Loss 0.125151 (avg:56.964654) \n",
      "Epoch: [7/10][7000/23040] Time 0.073 (avg:0.224) Loss 0.166802 (avg:56.264342) \n",
      "Epoch: [7/10][8000/23040] Time 0.545 (avg:0.225) Loss 53.864807 (avg:56.160087) \n",
      "Epoch: [7/10][9000/23040] Time 0.152 (avg:0.224) Loss 105.892029 (avg:56.005970) \n",
      "Epoch: [7/10][10000/23040] Time 0.261 (avg:0.224) Loss 167.954559 (avg:55.936709) \n",
      "Epoch: [7/10][11000/23040] Time 0.145 (avg:0.224) Loss 77.771385 (avg:55.956051) \n",
      "Epoch: [7/10][12000/23040] Time 0.058 (avg:0.223) Loss 0.616877 (avg:55.419989) \n",
      "Epoch: [7/10][13000/23040] Time 0.150 (avg:0.223) Loss 85.655846 (avg:55.395037) \n",
      "Epoch: [7/10][14000/23040] Time 0.146 (avg:0.223) Loss 42.198517 (avg:55.307884) \n",
      "Epoch: [7/10][15000/23040] Time 0.060 (avg:0.223) Loss 4.310833 (avg:55.265917) \n",
      "Epoch: [7/10][16000/23040] Time 0.303 (avg:0.223) Loss 50.365444 (avg:55.504357) \n",
      "Epoch: [7/10][17000/23040] Time 0.145 (avg:0.223) Loss 116.459702 (avg:55.525629) \n",
      "Epoch: [7/10][18000/23040] Time 0.145 (avg:0.223) Loss 76.131378 (avg:55.595513) \n",
      "Epoch: [7/10][19000/23040] Time 0.747 (avg:0.224) Loss 377.320190 (avg:56.008859) \n",
      "Epoch: [7/10][20000/23040] Time 0.301 (avg:0.224) Loss 16.991964 (avg:56.084048) \n",
      "Epoch: [7/10][21000/23040] Time 0.283 (avg:0.224) Loss 99.368355 (avg:56.049617) \n",
      "Epoch: [7/10][22000/23040] Time 0.060 (avg:0.223) Loss 1.360009 (avg:56.090577) \n",
      "Epoch: [7/10][23000/23040] Time 0.183 (avg:0.223) Loss 38.562038 (avg:56.032320) \n",
      "Epoch: [8/10][0/23040] Time 0.335 (avg:0.335) Loss 81.768745 (avg:81.768745) \n",
      "Epoch: [8/10][1000/23040] Time 0.061 (avg:0.222) Loss 0.478116 (avg:53.577518) \n",
      "Epoch: [8/10][2000/23040] Time 0.188 (avg:0.222) Loss 76.394012 (avg:53.299059) \n",
      "Epoch: [8/10][3000/23040] Time 0.143 (avg:0.223) Loss 44.733948 (avg:54.511854) \n",
      "Epoch: [8/10][4000/23040] Time 0.136 (avg:0.225) Loss 52.573067 (avg:54.498635) \n",
      "Epoch: [8/10][5000/23040] Time 0.190 (avg:0.224) Loss 39.716732 (avg:54.312439) \n",
      "Epoch: [8/10][6000/23040] Time 0.061 (avg:0.224) Loss 1.066657 (avg:54.789744) \n",
      "Epoch: [8/10][7000/23040] Time 0.291 (avg:0.224) Loss 18.141691 (avg:55.019777) \n",
      "Epoch: [8/10][8000/23040] Time 0.142 (avg:0.224) Loss 117.171783 (avg:55.452638) \n",
      "Epoch: [8/10][9000/23040] Time 0.397 (avg:0.223) Loss 20.404984 (avg:55.627556) \n",
      "Epoch: [8/10][10000/23040] Time 0.145 (avg:0.223) Loss 55.656643 (avg:55.726846) \n",
      "Epoch: [8/10][11000/23040] Time 0.525 (avg:0.223) Loss 135.258743 (avg:55.821092) \n",
      "Epoch: [8/10][12000/23040] Time 0.146 (avg:0.223) Loss 32.815468 (avg:55.933304) \n",
      "Epoch: [8/10][13000/23040] Time 0.395 (avg:0.224) Loss 17.704643 (avg:56.038308) \n",
      "Epoch: [8/10][14000/23040] Time 0.279 (avg:0.223) Loss 39.351940 (avg:56.277546) \n",
      "Epoch: [8/10][15000/23040] Time 0.192 (avg:0.223) Loss 49.329594 (avg:56.502902) \n",
      "Epoch: [8/10][16000/23040] Time 0.205 (avg:0.222) Loss 81.014549 (avg:56.213310) \n",
      "Epoch: [8/10][17000/23040] Time 0.742 (avg:0.223) Loss 145.646973 (avg:56.483499) \n",
      "Epoch: [8/10][18000/23040] Time 0.188 (avg:0.222) Loss 55.806419 (avg:56.221611) \n",
      "Epoch: [8/10][19000/23040] Time 0.137 (avg:0.222) Loss 39.801712 (avg:56.243062) \n",
      "Epoch: [8/10][20000/23040] Time 0.145 (avg:0.222) Loss 9.216458 (avg:56.170555) \n",
      "Epoch: [8/10][21000/23040] Time 0.188 (avg:0.222) Loss 78.228065 (avg:55.980257) \n",
      "Epoch: [8/10][22000/23040] Time 0.144 (avg:0.222) Loss 83.530212 (avg:55.834031) \n",
      "Epoch: [8/10][23000/23040] Time 0.069 (avg:0.222) Loss 0.669166 (avg:55.990015) \n",
      "Epoch: [9/10][0/23040] Time 0.256 (avg:0.256) Loss 16.468557 (avg:16.468557) \n",
      "Epoch: [9/10][1000/23040] Time 0.056 (avg:0.230) Loss 2.722968 (avg:58.375096) \n",
      "Epoch: [9/10][2000/23040] Time 0.148 (avg:0.228) Loss 95.802139 (avg:55.971231) \n",
      "Epoch: [9/10][3000/23040] Time 0.062 (avg:0.223) Loss 0.418171 (avg:55.861522) \n",
      "Epoch: [9/10][4000/23040] Time 0.072 (avg:0.224) Loss 0.982764 (avg:55.895377) \n",
      "Epoch: [9/10][5000/23040] Time 0.276 (avg:0.224) Loss 50.295135 (avg:55.421655) \n",
      "Epoch: [9/10][6000/23040] Time 0.401 (avg:0.225) Loss 88.426674 (avg:55.974098) \n",
      "Epoch: [9/10][7000/23040] Time 0.058 (avg:0.223) Loss 0.668361 (avg:55.402126) \n",
      "Epoch: [9/10][8000/23040] Time 0.249 (avg:0.225) Loss 352.040131 (avg:55.533882) \n",
      "Epoch: [9/10][9000/23040] Time 0.289 (avg:0.226) Loss 42.497337 (avg:56.072235) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9/10][10000/23040] Time 0.295 (avg:0.225) Loss 69.422668 (avg:55.946976) \n",
      "Epoch: [9/10][11000/23040] Time 0.277 (avg:0.225) Loss 26.263699 (avg:56.331337) \n",
      "Epoch: [9/10][12000/23040] Time 0.272 (avg:0.225) Loss 37.417488 (avg:56.245400) \n",
      "Epoch: [9/10][13000/23040] Time 0.407 (avg:0.225) Loss 54.748039 (avg:56.277142) \n",
      "Epoch: [9/10][14000/23040] Time 0.059 (avg:0.225) Loss 0.573868 (avg:56.289543) \n",
      "Epoch: [9/10][15000/23040] Time 0.140 (avg:0.225) Loss 146.935593 (avg:56.030427) \n",
      "Epoch: [9/10][16000/23040] Time 0.104 (avg:0.224) Loss 0.000000 (avg:55.835836) \n",
      "Epoch: [9/10][17000/23040] Time 0.285 (avg:0.224) Loss 19.137037 (avg:55.985707) \n",
      "Epoch: [9/10][18000/23040] Time 0.058 (avg:0.224) Loss 1.141878 (avg:56.000771) \n",
      "Epoch: [9/10][19000/23040] Time 0.153 (avg:0.224) Loss 38.539577 (avg:56.058059) \n",
      "Epoch: [9/10][20000/23040] Time 0.277 (avg:0.224) Loss 97.358780 (avg:56.156242) \n",
      "Epoch: [9/10][21000/23040] Time 0.080 (avg:0.224) Loss 0.000000 (avg:56.139506) \n",
      "Epoch: [9/10][22000/23040] Time 0.287 (avg:0.224) Loss 99.566017 (avg:56.004247) \n",
      "Epoch: [9/10][23000/23040] Time 0.140 (avg:0.223) Loss 82.686798 (avg:55.964587) \n",
      "Epoch: [10/10][0/23040] Time 0.143 (avg:0.143) Loss 0.068172 (avg:0.068172) \n",
      "Epoch: [10/10][1000/23040] Time 0.299 (avg:0.221) Loss 71.089264 (avg:55.765565) \n",
      "Epoch: [10/10][2000/23040] Time 0.435 (avg:0.224) Loss 83.408836 (avg:55.041680) \n",
      "Epoch: [10/10][3000/23040] Time 0.061 (avg:0.223) Loss 1.303893 (avg:55.011622) \n",
      "Epoch: [10/10][4000/23040] Time 0.059 (avg:0.221) Loss 2.685200 (avg:55.107845) \n",
      "Epoch: [10/10][5000/23040] Time 0.302 (avg:0.220) Loss 78.325645 (avg:54.913606) \n",
      "Epoch: [10/10][6000/23040] Time 0.749 (avg:0.219) Loss 210.105835 (avg:54.675366) \n",
      "Epoch: [10/10][7000/23040] Time 0.294 (avg:0.220) Loss 48.838322 (avg:55.028219) \n",
      "Epoch: [10/10][8000/23040] Time 0.060 (avg:0.221) Loss 5.393884 (avg:55.440671) \n",
      "Epoch: [10/10][9000/23040] Time 0.389 (avg:0.221) Loss 51.158615 (avg:55.536742) \n",
      "Epoch: [10/10][10000/23040] Time 0.384 (avg:0.222) Loss 58.483128 (avg:55.677663) \n",
      "Epoch: [10/10][11000/23040] Time 0.279 (avg:0.221) Loss 48.179173 (avg:55.679691) \n",
      "Epoch: [10/10][12000/23040] Time 0.529 (avg:0.221) Loss 70.580162 (avg:55.534952) \n",
      "Epoch: [10/10][13000/23040] Time 0.291 (avg:0.221) Loss 41.193272 (avg:55.383064) \n",
      "Epoch: [10/10][14000/23040] Time 0.102 (avg:0.221) Loss 0.689391 (avg:55.495982) \n",
      "Epoch: [10/10][15000/23040] Time 0.286 (avg:0.221) Loss 58.875801 (avg:55.862089) \n",
      "Epoch: [10/10][16000/23040] Time 0.146 (avg:0.222) Loss 96.039444 (avg:55.840929) \n",
      "Epoch: [10/10][17000/23040] Time 0.347 (avg:0.222) Loss 175.328979 (avg:55.991652) \n",
      "Epoch: [10/10][18000/23040] Time 0.281 (avg:0.222) Loss 26.359425 (avg:55.815931) \n",
      "Epoch: [10/10][19000/23040] Time 0.282 (avg:0.221) Loss 98.234039 (avg:55.691704) \n",
      "Epoch: [10/10][20000/23040] Time 0.187 (avg:0.222) Loss 73.447960 (avg:55.762946) \n",
      "Epoch: [10/10][21000/23040] Time 0.100 (avg:0.222) Loss 0.000000 (avg:55.820007) \n",
      "Epoch: [10/10][22000/23040] Time 0.252 (avg:0.222) Loss 57.460457 (avg:55.790566) \n",
      "Epoch: [10/10][23000/23040] Time 0.074 (avg:0.222) Loss 0.090243 (avg:55.921579) \n",
      "0/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/250047.png...\n",
      "1/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/77062.png...\n",
      "2/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/16068.png...\n",
      "3/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/107014.png...\n",
      "4/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/51084.png...\n",
      "5/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/238025.png...\n",
      "6/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/198087.png...\n",
      "7/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/189013.png...\n",
      "8/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/230063.png...\n",
      "9/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/279005.png...\n",
      "10/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/226060.png...\n",
      "11/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/246009.png...\n",
      "12/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/220003.png...\n",
      "13/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/230098.png...\n",
      "14/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/43051.png...\n",
      "15/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/188025.png...\n",
      "16/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/285022.png...\n",
      "17/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/159002.png...\n",
      "18/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/80085.png...\n",
      "19/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/189029.png...\n",
      "20/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/71076.png...\n",
      "21/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/106047.png...\n",
      "22/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/181021.png...\n",
      "23/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/267036.png...\n",
      "24/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/196027.png...\n",
      "25/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/208078.png...\n",
      "26/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/335088.png...\n",
      "27/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/207049.png...\n",
      "28/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/107045.png...\n",
      "29/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/268074.png...\n",
      "30/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/334025.png...\n",
      "31/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/41085.png...\n",
      "32/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/128035.png...\n",
      "33/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/226033.png...\n",
      "34/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/81066.png...\n",
      "35/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/161045.png...\n",
      "36/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/130066.png...\n",
      "37/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/160006.png...\n",
      "38/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/384022.png...\n",
      "39/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/97010.png...\n",
      "40/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/141048.png...\n",
      "41/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/28083.png...\n",
      "42/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/326085.png...\n",
      "43/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/147077.png...\n",
      "44/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/385022.png...\n",
      "45/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/235098.png...\n",
      "46/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/48025.png...\n",
      "47/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/112056.png...\n",
      "48/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/179084.png...\n",
      "49/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/232076.png...\n",
      "50/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/101084.png...\n",
      "51/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/326025.png...\n",
      "52/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/289011.png...\n",
      "53/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/49024.png...\n",
      "54/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/103078.png...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/29030.png...\n",
      "56/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/306052.png...\n",
      "57/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/250087.png...\n",
      "58/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/268048.png...\n",
      "59/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/130014.png...\n",
      "60/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/147080.png...\n",
      "61/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/118072.png...\n",
      "62/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/226043.png...\n",
      "63/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/104055.png...\n",
      "64/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/35049.png...\n",
      "65/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/281017.png...\n",
      "66/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/70090.png...\n",
      "67/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/189096.png...\n",
      "68/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/306051.png...\n",
      "69/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/196062.png...\n",
      "70/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/120003.png...\n",
      "71/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/118031.png...\n",
      "72/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/335094.png...\n",
      "73/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/45000.png...\n",
      "74/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/105027.png...\n",
      "75/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/368037.png...\n",
      "76/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/288024.png...\n",
      "77/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/376086.png...\n",
      "78/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/87015.png...\n",
      "79/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/43033.png...\n",
      "80/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/187099.png...\n",
      "81/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/247003.png...\n",
      "82/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/61034.png...\n",
      "83/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/207038.png...\n",
      "84/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/134049.png...\n",
      "85/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/17067.png...\n",
      "86/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/217090.png...\n",
      "87/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/16004.png...\n",
      "88/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/141012.png...\n",
      "89/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/3063.png...\n",
      "90/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/145059.png...\n",
      "91/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/243095.png...\n",
      "92/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/388018.png...\n",
      "93/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/100007.png...\n",
      "94/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/120093.png...\n",
      "95/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/70011.png...\n",
      "96/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/296028.png...\n",
      "97/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/257098.png...\n",
      "98/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/206097.png...\n",
      "99/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/79073.png...\n",
      "100/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/94095.png...\n",
      "101/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/217013.png...\n",
      "102/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/176051.png...\n",
      "103/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/372019.png...\n",
      "104/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/108036.png...\n",
      "105/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/223060.png...\n",
      "106/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/259060.png...\n",
      "107/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/209021.png...\n",
      "108/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/100039.png...\n",
      "109/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/69007.png...\n",
      "110/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/81095.png...\n",
      "111/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/309040.png...\n",
      "112/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/102062.png...\n",
      "113/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/35028.png...\n",
      "114/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/393035.png...\n",
      "115/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/69000.png...\n",
      "116/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/14085.png...\n",
      "117/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/6046.png...\n",
      "118/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/106005.png...\n",
      "119/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/140088.png...\n",
      "120/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/365072.png...\n",
      "121/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/196088.png...\n",
      "122/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/123057.png...\n",
      "123/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/112090.png...\n",
      "124/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/196040.png...\n",
      "125/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/185092.png...\n",
      "126/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/107072.png...\n",
      "127/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/33044.png...\n",
      "128/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/347031.png...\n",
      "129/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/253092.png...\n",
      "130/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/48017.png...\n",
      "131/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/78098.png...\n",
      "132/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/65084.png...\n",
      "133/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/80090.png...\n",
      "134/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/104010.png...\n",
      "135/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/228076.png...\n",
      "136/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/388067.png...\n",
      "137/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/302022.png...\n",
      "138/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/253016.png...\n",
      "139/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/145079.png...\n",
      "140/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/41006.png...\n",
      "141/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/15062.png...\n",
      "142/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/247012.png...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/20069.png...\n",
      "144/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/23050.png...\n",
      "145/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/183066.png...\n",
      "146/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/15011.png...\n",
      "147/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/296058.png...\n",
      "148/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/160067.png...\n",
      "149/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/277053.png...\n",
      "150/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/157087.png...\n",
      "151/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/2018.png...\n",
      "152/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/346016.png...\n",
      "153/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/140006.png...\n",
      "154/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/187058.png...\n",
      "155/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/189006.png...\n",
      "156/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/100099.png...\n",
      "157/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/103029.png...\n",
      "158/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/64061.png...\n",
      "159/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/225022.png...\n",
      "160/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/201080.png...\n",
      "161/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/175083.png...\n",
      "162/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/164046.png...\n",
      "163/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/258089.png...\n",
      "164/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/108004.png...\n",
      "165/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/36046.png...\n",
      "166/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/101027.png...\n",
      "167/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/290035.png...\n",
      "168/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/108069.png...\n",
      "169/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/103006.png...\n",
      "170/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/69022.png...\n",
      "171/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/41029.png...\n",
      "172/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/14092.png...\n",
      "173/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/109055.png...\n",
      "174/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/226022.png...\n",
      "175/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/10081.png...\n",
      "176/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/202000.png...\n",
      "177/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/5096.png...\n",
      "178/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/157032.png...\n",
      "179/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/384089.png...\n",
      "180/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/118015.png...\n",
      "181/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/134067.png...\n",
      "182/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/146074.png...\n",
      "183/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/41096.png...\n",
      "184/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/168084.png...\n",
      "185/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/71099.png...\n",
      "186/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/159022.png...\n",
      "187/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/388006.png...\n",
      "188/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/156054.png...\n",
      "189/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/8068.png...\n",
      "190/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/81090.png...\n",
      "191/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/249021.png...\n",
      "192/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/223004.png...\n",
      "193/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/92014.png...\n",
      "194/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/317043.png...\n",
      "195/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/206062.png...\n",
      "196/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/117025.png...\n",
      "197/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/163096.png...\n",
      "198/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/163004.png...\n",
      "199/200 eval /home/ygao26/Desktop/final/tmpRCF/RCF/epoch-10-testing-record-black/344010.png...\n",
      "The size of test images is 200\n",
      "The size of train images and labels is 28800, respectively\n",
      "The size of test images is 200\n",
      "The size of train images and labels is 28800, respectively\n",
      "The size of test images is 200\n",
      "The size of train images and labels is 28800, respectively\n",
      "The size of test images is 200\n",
      "The size of train images and labels is 28800, respectively\n",
      "The size of test images is 200\n",
      "The size of test images is 200\n",
      "The size of train images and labels is 28800, respectively\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Set up train validation split parameters\n",
    "    validation_split = 0.2\n",
    "    shuffle_dataset = True\n",
    "    random_seed= 42\n",
    "\n",
    "    filelist = join(data_folder, 'train_pair.lst')\n",
    "    # loop thru whole list of images and labels\n",
    "    with open(filelist, 'r') as f:\n",
    "        filelist = f.readlines()\n",
    "    # Create data indices for training and validation splits\n",
    "    dataset_size = len(filelist)\n",
    "    indices = list(range(dataset_size))\n",
    "    split_idx = int(np.floor(validation_split * dataset_size))\n",
    "    if shuffle_dataset:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split_idx:], indices[:split_idx]\n",
    "\n",
    "    # Creating data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = SubsetRandomSampler(val_indices)\n",
    "    train_dataset = BSDS_Dataloader(root=dft_datap, split= \"train\")\n",
    "    test_dataset = BSDS_Dataloader(root=dft_datap,  split= \"test\")\n",
    "    train_loader = DataLoader(\n",
    "    train_dataset, batch_size=dft_bs, sampler=train_sampler,\n",
    "    num_workers=0, drop_last=True)\n",
    "    val_loader = DataLoader(\n",
    "    train_dataset, batch_size=dft_bs, sampler=valid_sampler,\n",
    "    num_workers=0, drop_last=True)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=dft_bs,\n",
    "        num_workers=0, drop_last=True,shuffle=False)\n",
    "    with open(test_lst, 'r') as f:\n",
    "        test_list = f.readlines()\n",
    "    test_list = [split(i.rstrip())[1] for i in test_list]\n",
    "    assert len(test_list) == len(test_loader), \"%d vs %d\" % (len(test_list), len(test_loader))\n",
    "\n",
    "    # model\n",
    "    model = RCF()\n",
    "    model.cuda()\n",
    "    model.apply(weights_init) # Initialize weights\n",
    "    load_vgg16pretrain(model) # Update weights for each CNN layer based on VGG16 model\n",
    "#     load_vgg19pretrain(model) # Update weights for each CNN layer based on VGG19 model\n",
    "\n",
    "    \n",
    "    # Create optimizer to tune learning rate\n",
    "    # for layers at the same step\n",
    "    net_parameters_id = {}\n",
    "    net = model\n",
    "    for pname, p in net.named_parameters():\n",
    "        if pname in ['conv1_1.weight','conv1_2.weight',\n",
    "                     'conv2_1.weight','conv2_2.weight',\n",
    "                     'conv3_1.weight','conv3_2.weight','conv3_3.weight',\n",
    "                     'conv4_1.weight','conv4_2.weight','conv4_3.weight']:\n",
    "            # print(pname, 'lr:1 de:1')\n",
    "            if 'conv1-4.weight' not in net_parameters_id:\n",
    "                net_parameters_id['conv1-4.weight'] = []\n",
    "            net_parameters_id['conv1-4.weight'].append(p)\n",
    "        elif pname in ['conv1_1.bias','conv1_2.bias',\n",
    "                       'conv2_1.bias','conv2_2.bias',\n",
    "                       'conv3_1.bias','conv3_2.bias','conv3_3.bias',\n",
    "                       'conv4_1.bias','conv4_2.bias','conv4_3.bias']:\n",
    "            # print(pname, 'lr:2 de:0')\n",
    "            if 'conv1-4.bias' not in net_parameters_id:\n",
    "                net_parameters_id['conv1-4.bias'] = []\n",
    "            net_parameters_id['conv1-4.bias'].append(p)\n",
    "        elif pname in ['conv5_1.weight','conv5_2.weight','conv5_3.weight']:\n",
    "            # print(pname, 'lr:100 de:1')\n",
    "            if 'conv5.weight' not in net_parameters_id:\n",
    "                net_parameters_id['conv5.weight'] = []\n",
    "            net_parameters_id['conv5.weight'].append(p)\n",
    "        elif pname in ['conv5_1.bias','conv5_2.bias','conv5_3.bias'] :\n",
    "            # print(pname, 'lr:200 de:0')\n",
    "            if 'conv5.bias' not in net_parameters_id:\n",
    "                net_parameters_id['conv5.bias'] = []\n",
    "            net_parameters_id['conv5.bias'].append(p)\n",
    "        elif pname in ['conv1_1_down.weight','conv1_2_down.weight',\n",
    "                       'conv2_1_down.weight','conv2_2_down.weight',\n",
    "                       'conv3_1_down.weight','conv3_2_down.weight','conv3_3_down.weight',\n",
    "                       'conv4_1_down.weight','conv4_2_down.weight','conv4_3_down.weight',\n",
    "                       'conv5_1_down.weight','conv5_2_down.weight','conv5_3_down.weight']:\n",
    "            # print(pname, 'lr:0.1 de:1')\n",
    "            if 'conv_down_1-5.weight' not in net_parameters_id:\n",
    "                net_parameters_id['conv_down_1-5.weight'] = []\n",
    "            net_parameters_id['conv_down_1-5.weight'].append(p)\n",
    "        elif pname in ['conv1_1_down.bias','conv1_2_down.bias',\n",
    "                       'conv2_1_down.bias','conv2_2_down.bias',\n",
    "                       'conv3_1_down.bias','conv3_2_down.bias','conv3_3_down.bias',\n",
    "                       'conv4_1_down.bias','conv4_2_down.bias','conv4_3_down.bias',\n",
    "                       'conv5_1_down.bias','conv5_2_down.bias','conv5_3_down.bias']:\n",
    "            # print(pname, 'lr:0.2 de:0')\n",
    "            if 'conv_down_1-5.bias' not in net_parameters_id:\n",
    "                net_parameters_id['conv_down_1-5.bias'] = []\n",
    "            net_parameters_id['conv_down_1-5.bias'].append(p)\n",
    "        elif pname in ['score_dsn1.weight','score_dsn2.weight','score_dsn3.weight',\n",
    "                       'score_dsn4.weight','score_dsn5.weight']:\n",
    "            # print(pname, 'lr:0.01 de:1')\n",
    "            if 'score_dsn_1-5.weight' not in net_parameters_id:\n",
    "                net_parameters_id['score_dsn_1-5.weight'] = []\n",
    "            net_parameters_id['score_dsn_1-5.weight'].append(p)\n",
    "        elif pname in ['score_dsn1.bias','score_dsn2.bias','score_dsn3.bias',\n",
    "                       'score_dsn4.bias','score_dsn5.bias']:\n",
    "            # print(pname, 'lr:0.02 de:0')\n",
    "            if 'score_dsn_1-5.bias' not in net_parameters_id:\n",
    "                net_parameters_id['score_dsn_1-5.bias'] = []\n",
    "            net_parameters_id['score_dsn_1-5.bias'].append(p)\n",
    "        elif pname in ['score_final.weight']:\n",
    "            # print(pname, 'lr:0.001 de:1')\n",
    "            if 'score_final.weight' not in net_parameters_id:\n",
    "                net_parameters_id['score_final.weight'] = []\n",
    "            net_parameters_id['score_final.weight'].append(p)\n",
    "        elif pname in ['score_final.bias']:\n",
    "            # print(pname, 'lr:0.002 de:0')\n",
    "            if 'score_final.bias' not in net_parameters_id:\n",
    "                net_parameters_id['score_final.bias'] = []\n",
    "            net_parameters_id['score_final.bias'].append(p)\n",
    "\n",
    "    optimizer = torch.optim.SGD([\n",
    "            {'params': net_parameters_id['conv1-4.weight']      , 'lr': dft_lr*1    , 'weight_decay': dft_wd},\n",
    "            {'params': net_parameters_id['conv1-4.bias']        , 'lr': dft_lr*2    , 'weight_decay': 0.},\n",
    "            {'params': net_parameters_id['conv5.weight']        , 'lr': dft_lr*100  , 'weight_decay': dft_wd},\n",
    "            {'params': net_parameters_id['conv5.bias']          , 'lr': dft_lr*200  , 'weight_decay': 0.},\n",
    "            {'params': net_parameters_id['conv_down_1-5.weight'], 'lr': dft_lr*0.1  , 'weight_decay': dft_wd},\n",
    "            {'params': net_parameters_id['conv_down_1-5.bias']  , 'lr': dft_lr*0.2  , 'weight_decay': 0.},\n",
    "            {'params': net_parameters_id['score_dsn_1-5.weight'], 'lr': dft_lr*0.01 , 'weight_decay': dft_wd},\n",
    "            {'params': net_parameters_id['score_dsn_1-5.bias']  , 'lr': dft_lr*0.02 , 'weight_decay': 0.},\n",
    "            {'params': net_parameters_id['score_final.weight']  , 'lr': dft_lr*0.001, 'weight_decay': dft_wd},\n",
    "            {'params': net_parameters_id['score_final.bias']    , 'lr': dft_lr*0.002, 'weight_decay': 0.},\n",
    "        ], lr=dft_lr, momentum=dft_mmtum, weight_decay=dft_wd)\n",
    "    # Decays the learning rate of each parameter group by gamma \n",
    "    # every step_size epochs\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=dft_ss, gamma=dft_gm)\n",
    "\n",
    "    # log\n",
    "    log = Logger(join(tmp_dir, '%s-%d-log.txt' %('sgd',dft_lr)))\n",
    "    sys.stdout = log\n",
    "    \n",
    "    global train_loss, train_loss_detail, val_loss, val_loss_detail\n",
    "    # train/val loss parameters\n",
    "    train_loss = []\n",
    "    train_loss_detail = []\n",
    "    val_loss = []\n",
    "    val_loss_detail = []\n",
    "    for epoch in range(dft_step, dft_maxep):\n",
    "        if epoch == 1:\n",
    "            multiscale_test(model, test_loader, epoch=epoch, test_list=test_list,\n",
    "                 save_dir = join(tmp_dir, 'initial-testing-record'))\n",
    "        # Train the model\n",
    "        tr_avg_loss, tr_detail_loss = train(\n",
    "            train_loader, model, optimizer, epoch,\n",
    "            save_dir = join(tmp_dir, 'epoch-%d-training-record' % epoch))\n",
    "        # Collect validation loss\n",
    "        val_avg_loss, val_detail_loss = validation_loss(\n",
    "            val_loader, model, optimizer, epoch)\n",
    "        # Predict test sketch\n",
    "        multiscale_test(model, test_loader, epoch=epoch, test_list=test_list,\n",
    "            save_dir = join(tmp_dir, 'epoch-%d-testing-record' % epoch))\n",
    "        log.flush() # write log\n",
    "        # Save checkpoint\n",
    "        save_file = os.path.join(tmp_dir, 'checkpoint_epoch{}.pth'.format(epoch))\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "                         }, filename=save_file)\n",
    "        scheduler.step() # will adjust learning rate\n",
    "        # save train/val loss\n",
    "        train_loss.append(tr_avg_loss)\n",
    "        train_loss_detail += tr_detail_loss\n",
    "        val_loss.append(val_avg_loss)\n",
    "        val_loss_detail += val_detail_loss\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Detect overfitting/underfitting problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot train and validation loss\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.plot(train_loss, label='Training Loss')\n",
    "ax.plot(val_loss, label='Validation Loss')\n",
    "ax.set_title('Loss vs. Epochs', fontsize=16)\n",
    "ax.set_xlabel('Epochs', fontsize=14)\n",
    "ax.set_ylabel('Loss', fontsize=14)\n",
    "ax.legend(fontsize=14)\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Meature model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In edge detection world, there are two industry standard metrics to measure model performance. The first one is referred as optimal dataset scale (ODS) which employs a fixed threshold for all images in a dataset. The second is called optimal image scale (OIS) which selects an optimal threshold for each image. For the two metrics, the higher the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edges_eval_dir import edges_eval_dir\n",
    "edges_eval_dir(test_pre, test_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy eval_bdry.txt to root_dir and rename it to eval_bdry_rcf.txt. The job is done. The model performance will be compared in Edge Detection enhanced RCF.ipynb."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
